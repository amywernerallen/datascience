---
  title: 'Titantic Survival Exploration'
  author: "Amy Werner-Allen"
  output: html_document

---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

```{r echo=FALSE}
library(reshape)
library(stringr)
library(ggplot2)
library(corrplot)
library(Amelia)
```
  
### Data Exploration

First and foremost, we need to take a peek at the data. There are two datasets on the [Kaggle](https://www.kaggle.com/c/titanic) competition site: a training data set and a test data set. I chose to combine both to get a sense of what the data looks like. 

```{r}
setwd("~/Documents/Repositories/datascience/Kaggle/Titantic")
titanic.train = read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE)
titanic.train$IsTrain = TRUE
titanic.test = read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE)
titanic.test$IsTrain = FALSE

titanic.test$Survived = NA
titanic = rbind(titanic.train, titanic.test)
```

So what do we have?

```{r}
str(titanic)
```

We have *1309* data points: 891 training data points with survived in (0, 1) and 418 test data points with unknown survival outcomes (NA).

We have 13 variables: <br>

* **Passenger ID**: a primary key to identify a passenger
* **Survived**: indicator of surivival (will be NA when IsTrain is FALSE)
* **Class**: the class designation (1st, 2nd, or 3rd)
* **Name**: name of passenger
* **Sex**: sex of passenger
* **Age**: numeric age of passenger (decimal if less than 1 years old)
* **Sibling & Spouse**: number of siblings or spouses also aboard
* **Parent & Child**: number of parents or children also aboard
* **Ticket**: the ticket number
* **Fare**: how much the ticket cost
* **Cabin**: the cabin number of the passenger
* **Embarked**: the port of embarkment 
* **IsTrain**: indicates whether data is from training or test dataset

Now let's take a look at some key features to see exactly what we have.

We can get an overall picture of what data we are *missing* by using the missmap plot:

```{r}
missmap(titanic, y.labels = NULL, y.at = NULL, col = c("#CC3399", "#6699FF"), main = "Missing values vs observed")
```

We can easily see that **age** is missing quite a bit of values. We can start with age and take a quick distribution over all passengers:
```{r}
ggplot(titanic, aes(x=Age)) +
  geom_histogram(colour="darkblue", fill="#6699FF") +
  ggtitle("Age Distribution on Titanic") + 
  scale_fill_gradient(low = "light blue", high = "orchid4", guide=FALSE) +
  theme(panel.grid.minor = element_line(colour = "red", linetype = "dotted"), panel.background = element_rect(colour = "darkblue"))
```

About 20% of rows have no age information:
```{r}
sum(is.na(titanic$Age))
titanic$Age[is.na(titanic$Age)==TRUE] = mean(na.omit(titanic$Age))
```
In order to create a more complete data set, we can set these non-values equal to the average age on board the ship. 

What about **survival rates**? Looking globally, the chance of survival is around 40%:
```{r}
table(titanic$Survived)
```

We can also look at survival rates by different factors. Here we have survival rate by sex:
```{r}
ggplot(titanic, aes(Survived, fill=Sex)) + 
  geom_bar(width = 0.8) +
  scale_fill_manual(values=c("#CC3399", "#6699FF")) +
  theme(panel.grid.minor=element_blank(),panel.grid.major=element_blank()) +
  scale_x_continuous(breaks=c(0,1), labels=c("No", "Yes"))
```

We can see that women had a higher chance of surviving than men.

Here is survival rate by class:
```{r}
titanic$Pclass = as.factor(titanic$Pclass)

ggplot(titanic, aes(Survived, fill=Pclass)) + 
  geom_bar(width = 0.8) +
  scale_fill_manual(values=c("#CC3399", "#6699FF", "#66CC33")) +
  theme(panel.grid.minor=element_blank(),panel.grid.major=element_blank()) +
  scale_x_continuous(breaks=c(0,1), labels=c("No", "Yes"))
```

Being in first class gave you a better chance of survival, while being in third class meant you were much more likely *not* to survive. 

How about age? Lets create a factor for age based on numeric years.

```{r}
titanic$AgeF = "Infant"
titanic$AgeF[titanic$Age >=2] <- "Child"
titanic$AgeF[titanic$Age >=18] <- "Adult"
titanic$AgeF[titanic$Age >=50] <- "Elderly"

ggplot(titanic[!is.na(titanic$Age), ], aes(Survived, fill=AgeF)) + 
  geom_bar(width = 0.8) +
  scale_fill_manual(values=c("#CC3399", "#66CCCC", "#CC99FF", "#66CC33")) +
  theme(panel.grid.minor=element_blank(),panel.grid.major=element_blank()) +
  scale_x_continuous(breaks=c(0,1), labels=c("No", "Yes"))
```

We can see that infants had a higher chance of surviving, whereas the elderly had a lower chance. 

What about the **fare**, how much passengers spent on their tickets?

```{r}
ggplot(titanic, aes(x=Fare)) +
  geom_histogram(colour="darkblue", fill="#6699FF", binwidth=10) +
  ggtitle("Fare Distribution on Titanic") + 
  scale_fill_gradient(low = "light blue", high = "orchid4", guide=FALSE) +
  theme(panel.grid.minor = element_line(colour = "red", linetype = "dotted"), panel.background = element_rect(colour = "darkblue"))
```

We can see that there is a long tail on this distribution, with some passengers spending more than $500 on their ticket. The average price of a ticket was $33.

There is only one passenger with no fare information; this person is in the third class, so we can assign them the average fare:

```{r}
sum(is.na(titanic$Fare))
titanic$Fare[is.na(titanic$Fare)==TRUE] = mean(na.omit(titanic$Fare))
```

### Feature Selection

Now that we have an idea about the data completeness and distributions, let's start looking at **correlations** between different data elements.

```{r}
titanic$Pclass = as.numeric(titanic$Pclass)
titanic$SexN = 1
titanic$SexN[titanic$Sex=="male"] = 0
# 0 is male, 1 is female

titanic_numeric = titanic[, sapply(titanic, is.numeric)]
titanic_numeric = titanic_numeric[,-1]
M = cor(titanic_numeric, use="pairwise.complete.obs")
corrplot(M, cl.pos="b", tl.pos="d", tl.col = "black", tl.cex=0.75, type="upper")
```

We can see that survival is highly correlated with sex and class, and slightly with fare. We can also see that fare and class are highly correlated (so lower class passengers paid less money -- this makes sense). It also seems like higher class passengers were older, and those with siblings aboard also had parents or children.

### Simple Regression

Now, let's take a look at a simple **logistic regression** model. The factors we want to include are class, age, siblings, parents, fare, and sex.

```{r}
logitR = glm(Survived ~ Pclass + Age + SibSp + Parch + Fare + SexN, data = titanic_numeric, family = "binomial")
summary(logitR)
```

We can see from the summary that sex has the lowest p-value, followed by class, age, and number of siblings. 

```{r}
anova(logitR, test="Chisq")
```

<br>
Let's create a logistic model on the training set and use it on the test set to create some predictions. First, I divide up the data into a training set (75% of rows) and a test set (25% of rows). Then I create the model using the training set, and apply it to the test set:

```{r}
smp_size = floor(0.75 * 891)
set.seed(123)
train_ind = sample(891, size = smp_size)

training = na.omit(titanic_numeric)
training = training[train_ind, ]
test = training[-train_ind, ]

logit1 = glm(Survived ~ SexN + Pclass + Age + SibSp, data = training, family = "binomial")
fitted.results = predict(logit1,newdata=test,type='response')
fitted.results = ifelse(fitted.results > 0.5,1,0)

misClasificError = mean(fitted.results != test$Survived)
print(paste('Accuracy',1-misClasificError))
```

We can see that the accuracy of identifying the correct is roughly 75%. 

### Random Forests

Let's try a different method: a random forest. 

```{r}
library('party')
fit = cforest(as.factor(Survived) ~ Pclass + SexN + Age + SibSp + Parch + Fare,
                 data = training, 
                 controls=cforest_unbiased(ntree=2000, mtry=3))
Prediction = predict(fit, test, OOB=TRUE, type = "response")
misClasificError = mean(Prediction != test$Survived)
print(paste('Accuracy',1-misClasificError))
```

Accuracy on this method is higher, so let's go ahead and use this model for the real test data.

```{r}
training = titanic_numeric[1:891, ]
test = titanic_numeric[892:1309, ]
fit = cforest(as.factor(Survived) ~ Pclass + SexN + Age + SibSp + Parch + Fare,
                 data = training, 
                 controls=cforest_unbiased(ntree=2000, mtry=3))
Prediction = predict(fit, test, OOB=TRUE, type = "response")
```
write.csv(Prediction, file = "titanic_submission.csv", row.names=FALSE)